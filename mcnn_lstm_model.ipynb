{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import scipy.io as scio\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from generate_data import *\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as k\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "产生数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_num = 30\n",
    "col_num = 2000\n",
    "\n",
    "class Data(object):\n",
    "    '''\n",
    "    读取mat格式数据，由于每个故障数据数量不同，这里只截取前480000个数据\n",
    "    get_data()产生的数据为（2400，2000）的输入数据\n",
    "    get_label()产生的数据为（2400，1）的标签数据\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = self.get_data()\n",
    "        self.label = self.get_label()\n",
    "        \n",
    "    def file_list(self):\n",
    "        return os.listdir('../data/Drive_end_3/')\n",
    "    \n",
    "    def get_data(self):\n",
    "        file_list = self.file_list()\n",
    "        for i in range(len(file_list)):\n",
    "            file = scio.loadmat('../data/Drive_end_3/{}'.format(file_list[i]))\n",
    "            for k in file.keys():\n",
    "                file_matched = re.match('X\\d{3}_DE_time', k)\n",
    "                if file_matched:\n",
    "                    key = file_matched.group()\n",
    "            if i == 0:\n",
    "                data = np.array(file[key][0:480000].reshape(raw_num,col_num))\n",
    "            else:\n",
    "                data = np.vstack((data, file[key][0:480000].reshape((raw_num,col_num))))\n",
    "        return data\n",
    "    \n",
    "    def get_label(self):\n",
    "        file_list = self.file_list()\n",
    "        title = np.array([i.replace('.mat', '') for i in file_list])\n",
    "        label = title[:, np.newaxis]\n",
    "        label_copy = np.copy(label)\n",
    "        for _ in range(raw_num-1):\n",
    "            label = np.hstack((label, label_copy))\n",
    "        return label.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data()\n",
    "data = Data.data\n",
    "label = Data.label\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(label)\n",
    "\n",
    "'''\n",
    "这里的数据是原始数据，没有进行维纳滤波和归一化\n",
    "维纳滤波和归一化的试验已经再juypter上做了，可以打开再参考一下\n",
    "'''\n",
    "# 维纳滤波\n",
    "data_wiener = scipy.signal.wiener(data, mysize=3, noise=None)\n",
    "\n",
    "\n",
    "# 下采样\n",
    "index = np.arange(0,2000, 8)\n",
    "data_samp = data_wiener[:, index]\n",
    "print(data_samp.shape)  # 如果正确应该输入的是（2400，250）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_samp, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model():\n",
    "    \n",
    "    input_seq = Input(shape=(250,))\n",
    "    X = Reshape((1,250))(input_seq)\n",
    "    \n",
    "    # encoder1\n",
    "    ec1_layer1 = Conv1D(filters=50, kernel_size=20, strides=2,\n",
    "                       padding='valid', activation='tanh',\n",
    "                       data_format='channels_first')(X)\n",
    "    ec1_layer2 = Conv1D(filters=30, kernel_size=10, strides=2,\n",
    "                      padding='valid', activation='tanh',\n",
    "                      data_format='channels_first')(ec1_layer1)\n",
    "    ec1_outputs = MaxPooling1D(pool_size=2, strides=None, padding='valid',\n",
    "                             data_format='channels_first')(ec1_layer2)\n",
    "    \n",
    "    # encoder2\n",
    "    ec2_layer1 = Conv1D(filters=50, kernel_size=6, strides=1,\n",
    "                       padding='valid', activation='tanh',\n",
    "                       data_format='channels_first')(X)\n",
    "    ec2_layer2 = Conv1D(filters=40, kernel_size=6, strides=1,\n",
    "                      padding='valid', activation='tanh',\n",
    "                      data_format='channels_first')(ec2_layer1)\n",
    "    ec2_layer3 = MaxPooling1D(pool_size=2, strides=None, padding='valid',\n",
    "                             data_format='channels_first')(ec2_layer2)\n",
    "    ec2_layer4 = Conv1D(filters=30, kernel_size=6, strides=1,\n",
    "                       padding='valid', activation='tanh',\n",
    "                       data_format='channels_first')(ec2_layer3)\n",
    "    ec2_layer5 = Conv1D(filters=30, kernel_size=6, strides=2,\n",
    "                       padding='valid', activation='tanh',\n",
    "                       data_format='channels_first')(ec2_layer4)\n",
    "    ec2_outputs = MaxPooling1D(pool_size=2, strides=None, padding='valid',\n",
    "                             data_format='channels_first')(ec2_layer5)\n",
    "    \n",
    "    # 将两个自编码做点积\n",
    "    encoder = multiply([ec1_outputs, ec2_outputs])\n",
    "    \n",
    "    # 分类\n",
    "    dc_layer1 = LSTM(60, return_sequences=True)(encoder)\n",
    "    dc_layer2 = LSTM(30)(dc_layer1)\n",
    "    dc_layer3 = Dropout(0.5)(dc_layer2)\n",
    "    dc_layer4 = Dense(10, activation='softmax')(dc_layer3)\n",
    "    \n",
    "    model = Model(input_seq, dc_layer4)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues, normalize=False):\n",
    "    plt.imshow(cm , cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_mark = np.arange(len(classes))\n",
    "    plt.xticks(tick_mark, classes, rotation=40)\n",
    "    plt.yticks(tick_mark, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "        cm = '%.2f'%cm\n",
    "    thresh = cm.max()/2.0\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i,cm[i,j], horizontalalignment='center',color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predict label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = built_model()\n",
    "opt = Adam(lr=0.0006)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 5,\n",
    "                                            verbose = 1, factor=0.5, \n",
    "                                            min_lr = 0.00001)\n",
    "checkpoint = ModelCheckpoint('model/weights.{epoch:02d}-{val_acc:.4f}.hdf5', \n",
    "                            monitor='val_acc', \n",
    "                            verbose=0, \n",
    "                            save_best_only=True, \n",
    "                            save_weights_only=False, \n",
    "                            mode='max', \n",
    "                            period=1)\n",
    "history = model.fit(x=X_train, y=y_train, batch_size = 100, epochs=200, \n",
    "                    verbose=2, validation_data=(X_test, y_test),\n",
    "                    shuffle=True, initial_epoch=0, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(history.history['loss'], 'r', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'b', label='val_loss')\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('epochs', fontsize=20)\n",
    "plt.ylabel('loss', fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(history.history['acc'], 'r', label='acc')\n",
    "plt.plot(history.history['val_acc'], 'b', label='val_acc')\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('epochs', fontsize=20)\n",
    "plt.ylabel('accuracy', fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(12,9))\n",
    "y_pre = model.predict(X_test)\n",
    "label_pre = np.argmax(y_pre, axis=1)\n",
    "label_true = np.argmax(y_test, axis=1)\n",
    "confusion_mat = confusion_matrix(label_true, label_pre)\n",
    "plot_confusion_matrix(confusion_mat, classes=range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
